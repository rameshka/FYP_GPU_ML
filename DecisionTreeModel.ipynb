{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "import pylab as pl\n",
    "from sklearn import preprocessing\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>instructionCount</th>\n",
       "      <th>ilp32</th>\n",
       "      <th>ilp256</th>\n",
       "      <th>ilp2048</th>\n",
       "      <th>ilp65536</th>\n",
       "      <th>memops</th>\n",
       "      <th>ctrlops</th>\n",
       "      <th>intops</th>\n",
       "      <th>flops</th>\n",
       "      <th>...</th>\n",
       "      <th>lbdiv16</th>\n",
       "      <th>lbdiv32</th>\n",
       "      <th>lbdiv64</th>\n",
       "      <th>lbdiv128</th>\n",
       "      <th>lbdiv256</th>\n",
       "      <th>lbdiv512</th>\n",
       "      <th>lbdiv1024</th>\n",
       "      <th>probsize</th>\n",
       "      <th>CPU Time</th>\n",
       "      <th>GPU Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.523174e+07</td>\n",
       "      <td>1.076400e+10</td>\n",
       "      <td>4.852934</td>\n",
       "      <td>10.607886</td>\n",
       "      <td>74.282014</td>\n",
       "      <td>563.371791</td>\n",
       "      <td>0.712525</td>\n",
       "      <td>0.120555</td>\n",
       "      <td>0.740644</td>\n",
       "      <td>0.178620</td>\n",
       "      <td>...</td>\n",
       "      <td>1.062817e-03</td>\n",
       "      <td>1.741444e-03</td>\n",
       "      <td>2.145406e-03</td>\n",
       "      <td>2.501448e-03</td>\n",
       "      <td>3.088642e-03</td>\n",
       "      <td>2.871509e+01</td>\n",
       "      <td>5.409485e-03</td>\n",
       "      <td>4.152963e+05</td>\n",
       "      <td>22.571006</td>\n",
       "      <td>22.765411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.514525e+08</td>\n",
       "      <td>2.194167e+10</td>\n",
       "      <td>1.591059</td>\n",
       "      <td>8.206145</td>\n",
       "      <td>148.368694</td>\n",
       "      <td>1774.465515</td>\n",
       "      <td>0.105899</td>\n",
       "      <td>0.074426</td>\n",
       "      <td>0.113245</td>\n",
       "      <td>0.140009</td>\n",
       "      <td>...</td>\n",
       "      <td>3.909190e-03</td>\n",
       "      <td>6.358476e-03</td>\n",
       "      <td>7.161677e-03</td>\n",
       "      <td>7.357479e-03</td>\n",
       "      <td>7.849943e-03</td>\n",
       "      <td>2.615678e+02</td>\n",
       "      <td>1.167974e-02</td>\n",
       "      <td>1.335055e+06</td>\n",
       "      <td>34.422967</td>\n",
       "      <td>63.084143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.560000e+02</td>\n",
       "      <td>2.611762e+06</td>\n",
       "      <td>1.442210</td>\n",
       "      <td>1.918572</td>\n",
       "      <td>1.980879</td>\n",
       "      <td>2.570037</td>\n",
       "      <td>0.461629</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.518805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.016934</td>\n",
       "      <td>0.124418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.368000e+03</td>\n",
       "      <td>4.881504e+08</td>\n",
       "      <td>4.000063</td>\n",
       "      <td>4.458856</td>\n",
       "      <td>5.007727</td>\n",
       "      <td>5.773378</td>\n",
       "      <td>0.626536</td>\n",
       "      <td>0.072202</td>\n",
       "      <td>0.620232</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>2.773428</td>\n",
       "      <td>0.760976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000e+04</td>\n",
       "      <td>2.239865e+09</td>\n",
       "      <td>5.000074</td>\n",
       "      <td>9.059592</td>\n",
       "      <td>9.687678</td>\n",
       "      <td>14.166241</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.100001</td>\n",
       "      <td>0.777779</td>\n",
       "      <td>0.185172</td>\n",
       "      <td>...</td>\n",
       "      <td>6.560000e-08</td>\n",
       "      <td>1.310000e-07</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>4.750000e-07</td>\n",
       "      <td>6.680000e-07</td>\n",
       "      <td>7.420000e-07</td>\n",
       "      <td>8.350000e-07</td>\n",
       "      <td>2.970000e+02</td>\n",
       "      <td>10.475384</td>\n",
       "      <td>3.324654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.733445e+05</td>\n",
       "      <td>8.364610e+09</td>\n",
       "      <td>6.141176</td>\n",
       "      <td>13.489561</td>\n",
       "      <td>33.253687</td>\n",
       "      <td>255.673730</td>\n",
       "      <td>0.808426</td>\n",
       "      <td>0.145731</td>\n",
       "      <td>0.831889</td>\n",
       "      <td>0.245617</td>\n",
       "      <td>...</td>\n",
       "      <td>1.185536e-04</td>\n",
       "      <td>1.929116e-04</td>\n",
       "      <td>2.952818e-04</td>\n",
       "      <td>3.926128e-04</td>\n",
       "      <td>3.956721e-04</td>\n",
       "      <td>5.597367e-04</td>\n",
       "      <td>6.199144e-04</td>\n",
       "      <td>2.469500e+03</td>\n",
       "      <td>28.668817</td>\n",
       "      <td>14.161183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+09</td>\n",
       "      <td>1.374371e+11</td>\n",
       "      <td>7.197260</td>\n",
       "      <td>37.911765</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>9023.000000</td>\n",
       "      <td>0.890129</td>\n",
       "      <td>0.307693</td>\n",
       "      <td>0.886846</td>\n",
       "      <td>0.523809</td>\n",
       "      <td>...</td>\n",
       "      <td>2.225168e-02</td>\n",
       "      <td>3.323731e-02</td>\n",
       "      <td>3.596328e-02</td>\n",
       "      <td>3.596328e-02</td>\n",
       "      <td>3.596328e-02</td>\n",
       "      <td>2.383000e+03</td>\n",
       "      <td>3.705571e-02</td>\n",
       "      <td>6.944444e+06</td>\n",
       "      <td>169.931417</td>\n",
       "      <td>412.397738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Input  instructionCount      ilp32     ilp256     ilp2048  \\\n",
       "count  8.300000e+01      8.300000e+01  83.000000  83.000000   83.000000   \n",
       "mean   3.523174e+07      1.076400e+10   4.852934  10.607886   74.282014   \n",
       "std    1.514525e+08      2.194167e+10   1.591059   8.206145  148.368694   \n",
       "min    2.560000e+02      2.611762e+06   1.442210   1.918572    1.980879   \n",
       "25%    1.368000e+03      4.881504e+08   4.000063   4.458856    5.007727   \n",
       "50%    2.000000e+04      2.239865e+09   5.000074   9.059592    9.687678   \n",
       "75%    1.733445e+05      8.364610e+09   6.141176  13.489561   33.253687   \n",
       "max    1.000000e+09      1.374371e+11   7.197260  37.911765  534.000000   \n",
       "\n",
       "          ilp65536     memops    ctrlops     intops      flops     ...      \\\n",
       "count    83.000000  83.000000  83.000000  83.000000  83.000000     ...       \n",
       "mean    563.371791   0.712525   0.120555   0.740644   0.178620     ...       \n",
       "std    1774.465515   0.105899   0.074426   0.113245   0.140009     ...       \n",
       "min       2.570037   0.461629   0.007327   0.518805   0.000000     ...       \n",
       "25%       5.773378   0.626536   0.072202   0.620232   0.050000     ...       \n",
       "50%      14.166241   0.718750   0.100001   0.777779   0.185172     ...       \n",
       "75%     255.673730   0.808426   0.145731   0.831889   0.245617     ...       \n",
       "max    9023.000000   0.890129   0.307693   0.886846   0.523809     ...       \n",
       "\n",
       "            lbdiv16       lbdiv32       lbdiv64      lbdiv128      lbdiv256  \\\n",
       "count  8.300000e+01  8.300000e+01  8.300000e+01  8.300000e+01  8.300000e+01   \n",
       "mean   1.062817e-03  1.741444e-03  2.145406e-03  2.501448e-03  3.088642e-03   \n",
       "std    3.909190e-03  6.358476e-03  7.161677e-03  7.357479e-03  7.849943e-03   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    6.560000e-08  1.310000e-07  2.630000e-07  4.750000e-07  6.680000e-07   \n",
       "75%    1.185536e-04  1.929116e-04  2.952818e-04  3.926128e-04  3.956721e-04   \n",
       "max    2.225168e-02  3.323731e-02  3.596328e-02  3.596328e-02  3.596328e-02   \n",
       "\n",
       "           lbdiv512     lbdiv1024      probsize    CPU Time    GPU Time  \n",
       "count  8.300000e+01  8.300000e+01  8.300000e+01   83.000000   83.000000  \n",
       "mean   2.871509e+01  5.409485e-03  4.152963e+05   22.571006   22.765411  \n",
       "std    2.615678e+02  1.167974e-02  1.335055e+06   34.422967   63.084143  \n",
       "min    0.000000e+00  0.000000e+00  2.000000e+00    0.016934    0.124418  \n",
       "25%    0.000000e+00  0.000000e+00  9.000000e+00    2.773428    0.760976  \n",
       "50%    7.420000e-07  8.350000e-07  2.970000e+02   10.475384    3.324654  \n",
       "75%    5.597367e-04  6.199144e-04  2.469500e+03   28.668817   14.161183  \n",
       "max    2.383000e+03  3.705571e-02  6.944444e+06  169.931417  412.397738  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "df = pd.DataFrame(data) # Converting data to Panda DataFrame\n",
    "df.describe() #gives statistics about the columns of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate traindata and test data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "yes = len(data[data.Class == \"Y\"])\n",
    "No = len(data[data.Class == \"N\"])\n",
    "\n",
    "print yes\n",
    "print No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing data to reside in between 0 and 1 using MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>memops</th>\n",
       "      <th>ctrlops</th>\n",
       "      <th>intops</th>\n",
       "      <th>flops</th>\n",
       "      <th>coldref fraction</th>\n",
       "      <th>resuseDist2 fraction</th>\n",
       "      <th>sfp</th>\n",
       "      <th>dfp</th>\n",
       "      <th>noconflict</th>\n",
       "      <th>broadCast</th>\n",
       "      <th>...</th>\n",
       "      <th>lbdiv512</th>\n",
       "      <th>lbdiv1024</th>\n",
       "      <th>instructionCount</th>\n",
       "      <th>blocks</th>\n",
       "      <th>pages</th>\n",
       "      <th>ilp32</th>\n",
       "      <th>ilp256</th>\n",
       "      <th>ilp2048</th>\n",
       "      <th>ilp65536</th>\n",
       "      <th>probsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.820424</td>\n",
       "      <td>0.051388</td>\n",
       "      <td>0.846086</td>\n",
       "      <td>0.256314</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.625033</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067171</td>\n",
       "      <td>0.899166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>3.075188e-07</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.878528</td>\n",
       "      <td>0.308208</td>\n",
       "      <td>0.020860</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.001486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.820468</td>\n",
       "      <td>0.051335</td>\n",
       "      <td>0.846120</td>\n",
       "      <td>0.256362</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.625014</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051082</td>\n",
       "      <td>0.924311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>3.082595e-07</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.878686</td>\n",
       "      <td>0.308042</td>\n",
       "      <td>0.020786</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.001305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.820476</td>\n",
       "      <td>0.051325</td>\n",
       "      <td>0.846126</td>\n",
       "      <td>0.256371</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.625011</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051449</td>\n",
       "      <td>0.928102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>3.083987e-07</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.819275</td>\n",
       "      <td>0.308012</td>\n",
       "      <td>0.020772</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.001276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.666661</td>\n",
       "      <td>0.074120</td>\n",
       "      <td>0.666661</td>\n",
       "      <td>0.185172</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.555550</td>\n",
       "      <td>0.599922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062615</td>\n",
       "      <td>0.937385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004560</td>\n",
       "      <td>0.009120</td>\n",
       "      <td>0.168962</td>\n",
       "      <td>3.181174e-05</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.922278</td>\n",
       "      <td>0.197610</td>\n",
       "      <td>0.013819</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>0.001278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.642840</td>\n",
       "      <td>0.071516</td>\n",
       "      <td>0.678563</td>\n",
       "      <td>0.178545</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.555543</td>\n",
       "      <td>0.599844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062729</td>\n",
       "      <td>0.937271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017669</td>\n",
       "      <td>0.035338</td>\n",
       "      <td>0.021787</td>\n",
       "      <td>1.583899e-05</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.965575</td>\n",
       "      <td>0.207809</td>\n",
       "      <td>0.015128</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.001461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     memops   ctrlops    intops     flops  coldref fraction  \\\n",
       "0  0.820424  0.051388  0.846086  0.256314          0.000981   \n",
       "1  0.820468  0.051335  0.846120  0.256362          0.000979   \n",
       "2  0.820476  0.051325  0.846126  0.256371          0.000978   \n",
       "3  0.666661  0.074120  0.666661  0.185172          0.000009   \n",
       "4  0.642840  0.071516  0.678563  0.178545          0.000019   \n",
       "\n",
       "   resuseDist2 fraction       sfp  dfp  noconflict  broadCast    ...     \\\n",
       "0              0.625033  0.400000  0.0    0.067171   0.899166    ...      \n",
       "1              0.625014  0.400000  0.0    0.051082   0.924311    ...      \n",
       "2              0.625011  0.400000  0.0    0.051449   0.928102    ...      \n",
       "3              0.555550  0.599922  0.0    0.062615   0.937385    ...      \n",
       "4              0.555543  0.599844  0.0    0.062729   0.937271    ...      \n",
       "\n",
       "   lbdiv512  lbdiv1024  instructionCount        blocks     pages     ilp32  \\\n",
       "0  0.000000   0.000000          0.000172  3.075188e-07  0.000008  0.878528   \n",
       "1  0.000000   0.000000          0.000743  3.082595e-07  0.000008  0.878686   \n",
       "2  0.000000   0.000000          0.001116  3.083987e-07  0.000008  0.819275   \n",
       "3  0.004560   0.009120          0.168962  3.181174e-05  0.000835  0.922278   \n",
       "4  0.017669   0.035338          0.021787  1.583899e-05  0.000415  0.965575   \n",
       "\n",
       "     ilp256   ilp2048  ilp65536  probsize  \n",
       "0  0.308208  0.020860  0.001486  0.001486  \n",
       "1  0.308042  0.020786  0.001305  0.001305  \n",
       "2  0.308012  0.020772  0.001276  0.001276  \n",
       "3  0.197610  0.013819  0.001278  0.001278  \n",
       "4  0.207809  0.015128  0.001461  0.001461  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "dfTest = min_max_scaler.fit_transform(df[['instructionCount','blocks','pages',\n",
    "                                          'ilp32','ilp256','ilp2048','ilp65536','probsize']])\n",
    "\n",
    "X_train = df.drop(['CPU Time','GPU Time','Class','dataSet','Input','instructionCount','ilp32','ilp32'\n",
    "                ,'ilp256','ilp2048','ilp65536','pages','blocks','coldref','reuseDist2','probsize'],axis=1)\n",
    "\n",
    "X_train['instructionCount'] = pd.DataFrame({'instructionCount':dfTest[:,0]})\n",
    "X_train['blocks']           = pd.DataFrame({'blocks':dfTest[:,1]})\n",
    "X_train['pages']            = pd.DataFrame({'pages':dfTest[:,2]})\n",
    "X_train['ilp32']            = pd.DataFrame({'ilp32':dfTest[:,3]})\n",
    "X_train['ilp256']           = pd.DataFrame({'ilp256':dfTest[:,4]})\n",
    "X_train['ilp2048']          = pd.DataFrame({'ilp2048':dfTest[:,5]})\n",
    "X_train['ilp65536']         = pd.DataFrame({'ilp65536':dfTest[:,6]})\n",
    "X_train['probsize']         = pd.DataFrame({'probsize':dfTest[:,6]})\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = df['Class']\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "Y_train = np.asarray(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test dataset\n",
    "\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "df_test = pd.DataFrame(test) #reading test dataset\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "dfTest_Test = min_max_scaler.fit_transform(df_test[['instructionCount','blocks','pages',\n",
    "                                               'ilp32','ilp256','ilp2048','ilp65536','probsize']])\n",
    "\n",
    "X_test = df_test.drop(['CPU Time','GPU Time','Class','dataSet','Input','instructionCount','ilp32','ilp32'\n",
    "                   ,'ilp256','ilp2048','ilp65536','pages','blocks','coldref','reuseDist2','probsize'],axis=1)\n",
    "\n",
    "X_test['instructionCount'] = pd.DataFrame({'instructionCount':dfTest_Test[:,0]})\n",
    "X_test['blocks'] = pd.DataFrame({'blocks':dfTest_Test[:,1]})\n",
    "X_test['pages'] = pd.DataFrame({'pages':dfTest_Test[:,2]})\n",
    "X_test['ilp32'] = pd.DataFrame({'ilp32':dfTest_Test[:,3]})\n",
    "X_test['ilp256'] = pd.DataFrame({'ilp256':dfTest_Test[:,4]})\n",
    "X_test['ilp2048'] = pd.DataFrame({'ilp2048':dfTest_Test[:,5]})\n",
    "X_test['ilp65536'] = pd.DataFrame({'ilp65536':dfTest_Test[:,6]})\n",
    "X_test['probsize'] = pd.DataFrame({'probsize':dfTest_Test[:,6]})\n",
    "\n",
    "Y_test =df_test['Class'] # We create our label\n",
    "\n",
    "X_test = np.asarray(X_test)\n",
    "Y_test = np.asarray(Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembled Bagging Decison Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "         bootstrap_features=True, max_features=1.0, max_samples=1.0,\n",
       "         n_estimators=11, n_jobs=-1, oob_score=False, random_state=None,\n",
       "         verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baggingClassifier = ensemble.BaggingClassifier(n_estimators=11,bootstrap_features=True,n_jobs=-1)\n",
    "baggingClassifier.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78571429 0.82142857 0.55555556]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(baggingClassifier, X_train, Y_train)\n",
    "print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N' 'N' 'N' 'Y' 'Y' 'N']\n",
      "['N' 'N' 'N' 'Y' 'Y' 'Y']\n"
     ]
    }
   ],
   "source": [
    "print baggingClassifier.predict(X_test)\n",
    "print Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
