{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "import pylab as pl\n",
    "from sklearn import preprocessing\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import svm\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"group1.csv\")\n",
    "df1 = pd.DataFrame(data1) # Converting data to Panda DataFrame\n",
    "data2 = pd.read_csv(\"group2.csv\")\n",
    "df2 = pd.DataFrame(data2) # Converting data to Panda DataFrame\n",
    "data3 = pd.read_csv(\"group3.csv\")\n",
    "df3 = pd.DataFrame(data3) # Converting data to Panda DataFrame\n",
    "data4 = pd.read_csv(\"group4.csv\")\n",
    "df4 = pd.DataFrame(data4) # Converting data to Panda DataFrame\n",
    "data5 = pd.read_csv(\"group5.csv\")\n",
    "df5 = pd.DataFrame(data5) # Converting data to Panda DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight all the features by instruction count rather than a separate instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = df1\n",
    "\n",
    "Weighted_X1 = X_1[[\"ilp32\",'ilp256','ilp2048','ilp65536','memops','ctrlops','intops','flops','coldref fraction','resuseDist2 fraction','sfp','dfp','noconflict','broadCast','coalesced',\n",
    " 'shMemBw',\n",
    " 'gMemBw',\n",
    " 'blocks',\n",
    " 'pages',\n",
    " 'lipRate',\n",
    " 'mulf',\n",
    " 'divf',\n",
    " 'specialFn',\n",
    " 'lbdiv16',\n",
    " 'lbdiv32',\n",
    " 'lbdiv64',\n",
    " 'lbdiv128',\n",
    " 'lbdiv256',\n",
    " 'lbdiv512',\n",
    " 'lbdiv1024']].multiply(df1[\"instructionCount\"], axis=\"index\")\n",
    "\n",
    "X_2 = df2\n",
    "\n",
    "Weighted_X2 = X_2[[\"ilp32\",'ilp256','ilp2048','ilp65536','memops','ctrlops','intops','flops','coldref fraction','resuseDist2 fraction','sfp','dfp','noconflict','broadCast','coalesced',\n",
    " 'shMemBw',\n",
    " 'gMemBw',\n",
    " 'blocks',\n",
    " 'pages',\n",
    " 'lipRate',\n",
    " 'mulf',\n",
    " 'divf',\n",
    " 'specialFn',\n",
    " 'lbdiv16',\n",
    " 'lbdiv32',\n",
    " 'lbdiv64',\n",
    " 'lbdiv128',\n",
    " 'lbdiv256',\n",
    " 'lbdiv512',\n",
    " 'lbdiv1024']].multiply(df2[\"instructionCount\"], axis=\"index\")\n",
    "\n",
    "X_3 = df3\n",
    "\n",
    "Weighted_X3 = X_3[[\"ilp32\",'ilp256','ilp2048','ilp65536','memops','ctrlops','intops','flops','coldref fraction','resuseDist2 fraction','sfp','dfp','noconflict','broadCast','coalesced',\n",
    " 'shMemBw',\n",
    " 'gMemBw',\n",
    " 'blocks',\n",
    " 'pages',\n",
    " 'lipRate',\n",
    " 'mulf',\n",
    " 'divf',\n",
    " 'specialFn',\n",
    " 'lbdiv16',\n",
    " 'lbdiv32',\n",
    " 'lbdiv64',\n",
    " 'lbdiv128',\n",
    " 'lbdiv256',\n",
    " 'lbdiv512',\n",
    " 'lbdiv1024']].multiply(df3[\"instructionCount\"], axis=\"index\")\n",
    "\n",
    "X_4 = df4\n",
    "\n",
    "Weighted_X4 = X_4[[\"ilp32\",'ilp256','ilp2048','ilp65536','memops','ctrlops','intops','flops','coldref fraction','resuseDist2 fraction','sfp','dfp','noconflict','broadCast','coalesced',\n",
    " 'shMemBw',\n",
    " 'gMemBw',\n",
    " 'blocks',\n",
    " 'pages',\n",
    " 'lipRate',\n",
    " 'mulf',\n",
    " 'divf',\n",
    " 'specialFn',\n",
    " 'lbdiv16',\n",
    " 'lbdiv32',\n",
    " 'lbdiv64',\n",
    " 'lbdiv128',\n",
    " 'lbdiv256',\n",
    " 'lbdiv512',\n",
    " 'lbdiv1024']].multiply(df4[\"instructionCount\"], axis=\"index\")\n",
    "\n",
    "X_5 = df5\n",
    "\n",
    "Weighted_X5 = X_5[[\"ilp32\",'ilp256','ilp2048','ilp65536','memops','ctrlops','intops','flops','coldref fraction','resuseDist2 fraction','sfp','dfp','noconflict','broadCast','coalesced',\n",
    " 'shMemBw',\n",
    " 'gMemBw',\n",
    " 'blocks',\n",
    " 'pages',\n",
    " 'lipRate',\n",
    " 'mulf',\n",
    " 'divf',\n",
    " 'specialFn',\n",
    " 'lbdiv16',\n",
    " 'lbdiv32',\n",
    " 'lbdiv64',\n",
    " 'lbdiv128',\n",
    " 'lbdiv256',\n",
    " 'lbdiv512',\n",
    " 'lbdiv1024']].multiply(df5[\"instructionCount\"], axis=\"index\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train1 = df1['Class']\n",
    "Y_train2 = df2['Class']\n",
    "Y_train3 = df3['Class']\n",
    "Y_train4 = df4['Class']\n",
    "Y_train5 = df5['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomForestT1 = RandomForestClassifier(n_estimators=20,n_jobs=-1,random_state=0)\n",
    "# randomForestT2 = RandomForestClassifier(n_estimators=20,n_jobs=-1,random_state=0)\n",
    "# randomForestT3 = RandomForestClassifier(n_estimators=20,n_jobs=-1,random_state=0)\n",
    "# randomForestT4 = RandomForestClassifier(n_estimators=20,n_jobs=-1,random_state=0)\n",
    "# randomForestT5 = RandomForestClassifier(n_estimators=20,n_jobs=-1,random_state=0)\n",
    "\n",
    "# randomForestT1.fit(Weighted_X1,Y_train1)\n",
    "# randomForestT2.fit(Weighted_X2,Y_train2)\n",
    "# randomForestT3.fit(Weighted_X3,Y_train3)\n",
    "# randomForestT4.fit(Weighted_X4,Y_train4)\n",
    "# randomForestT5.fit(Weighted_X5,Y_train5)\n",
    "\n",
    "# model1 = SelectFromModel(randomForestT1, prefit=True)\n",
    "# model2 = SelectFromModel(randomForestT2, prefit=True)\n",
    "# model3 = SelectFromModel(randomForestT3, prefit=True)\n",
    "# model4 = SelectFromModel(randomForestT4, prefit=True)\n",
    "# model5 = SelectFromModel(randomForestT5, prefit=True)\n",
    "# idxs_selected1 = model1.get_support(indices=True)\n",
    "# idxs_selected2 = model2.get_support(indices=True)\n",
    "# idxs_selected3 = model3.get_support(indices=True)\n",
    "# idxs_selected4 = model4.get_support(indices=True)\n",
    "# idxs_selected5 = model5.get_support(indices=True)\n",
    "# X_new1 = model1.transform(Weighted_X1)\n",
    "# X_new2 = model2.transform(Weighted_X2)\n",
    "# X_new3 = model3.transform(Weighted_X3)\n",
    "# X_new4 = model4.transform(Weighted_X4)\n",
    "# X_new5 = model5.transform(Weighted_X5)\n",
    "\n",
    "selector1 = SelectKBest(chi2, k=25)\n",
    "X_new1 =selector1.fit_transform(Weighted_X1, Y_train1)\n",
    "idxs_selected1 = selector1.get_support(indices=True)\n",
    "selector2 = SelectKBest(chi2, k=25)\n",
    "X_new2 =selector2.fit_transform(Weighted_X2, Y_train2)\n",
    "idxs_selected2 = selector2.get_support(indices=True)\n",
    "selector3 = SelectKBest(chi2, k=25)\n",
    "X_new3 =selector3.fit_transform(Weighted_X3, Y_train3)\n",
    "idxs_selected3 = selector3.get_support(indices=True)\n",
    "selector4 = SelectKBest(chi2, k=25)\n",
    "X_new4 =selector4.fit_transform(Weighted_X4, Y_train4)\n",
    "idxs_selected4 = selector4.get_support(indices=True)\n",
    "selector5 = SelectKBest(chi2, k=25)\n",
    "X_new5 =selector5.fit_transform(Weighted_X5, Y_train5)\n",
    "idxs_selected5 = selector5.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Test Data from unseen Data (Guaranteed_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"test.csv\")\n",
    "df_test = pd.DataFrame(data_test) # Converting data to Panda DataFrame\n",
    "#df_test = df_test.sample(20)\n",
    "#df_test.head() #gives statistics about the columns of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = df_test\n",
    "Weighted_XTest = X_test[[\"ilp32\",'ilp256','ilp2048','ilp65536','memops','ctrlops','intops','flops',\n",
    " 'coldref fraction',\n",
    " 'resuseDist2 fraction',\n",
    " 'sfp',\n",
    " 'dfp',\n",
    " 'noconflict',\n",
    " 'broadCast',\n",
    " 'coalesced',\n",
    " 'shMemBw',\n",
    " 'gMemBw',\n",
    " 'blocks',\n",
    " 'pages',\n",
    " 'lipRate',\n",
    " 'mulf',\n",
    " 'divf',\n",
    " 'specialFn',\n",
    " 'lbdiv16',\n",
    "\n",
    " 'lbdiv32',\n",
    " 'lbdiv64',\n",
    " 'lbdiv128',\n",
    " 'lbdiv256',\n",
    " 'lbdiv512',\n",
    " 'lbdiv1024']].multiply(df_test[\"instructionCount\"], axis=\"index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "         bootstrap_features=True, max_features=1.0, max_samples=1.0,\n",
       "         n_estimators=11, n_jobs=-1, oob_score=False, random_state=0,\n",
       "         verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baggingClassifier1 = ensemble.BaggingClassifier(n_estimators=11,bootstrap_features=True,n_jobs=-1,random_state=0)\n",
    "baggingClassifier1.fit(X_new1,Y_train1)\n",
    "baggingClassifier2 = ensemble.BaggingClassifier(n_estimators=11,bootstrap_features=True,n_jobs=-1,random_state=0)\n",
    "baggingClassifier2.fit(X_new2,Y_train2)\n",
    "baggingClassifier3 = ensemble.BaggingClassifier(n_estimators=11,bootstrap_features=True,n_jobs=-1,random_state=0)\n",
    "baggingClassifier3.fit(X_new3,Y_train3)\n",
    "baggingClassifier4 = ensemble.BaggingClassifier(n_estimators=11,bootstrap_features=True,n_jobs=-1,random_state=0)\n",
    "baggingClassifier4.fit(X_new4,Y_train4)\n",
    "baggingClassifier5 = ensemble.BaggingClassifier(n_estimators=11,bootstrap_features=True,n_jobs=-1,random_state=0)\n",
    "baggingClassifier5.fit(X_new5,Y_train5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83571429 0.68571429 0.71428571]\n"
     ]
    }
   ],
   "source": [
    "scores1 = cross_val_score(baggingClassifier1, X_new1, Y_train1)\n",
    "scores2 = cross_val_score(baggingClassifier2, X_new2, Y_train2)\n",
    "scores3 = cross_val_score(baggingClassifier3, X_new3, Y_train3)\n",
    "scores4 = cross_val_score(baggingClassifier4, X_new4, Y_train4)\n",
    "scores5 = cross_val_score(baggingClassifier5, X_new5, Y_train5)\n",
    "\n",
    "avg = (scores1 + scores2 +scores3 + scores4 + scores5)/5\n",
    "print avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1]\n",
      "[0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1]\n",
      "[0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "[2 2 2 4 3 3 2 3 2 2 2 1 1 2 2 2 2 2 1 1 5 5 5 4 4 4 3 4 4]\n",
      "['N' 'N' 'N' 'Y' 'Y' 'Y' 'N' 'Y' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y']\n",
      "['N' 'N' 'N' 'N' 'Y' 'Y' 'Y' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y']\n"
     ]
    }
   ],
   "source": [
    "prediction1 = baggingClassifier1.predict(Weighted_XTest[Weighted_XTest.columns[idxs_selected1]])\n",
    "print (prediction1)\n",
    "prediction2 = baggingClassifier2.predict(Weighted_XTest[Weighted_XTest.columns[idxs_selected2]])\n",
    "print (prediction2)\n",
    "prediction3 = baggingClassifier3.predict(Weighted_XTest[Weighted_XTest.columns[idxs_selected3]])\n",
    "print (prediction3)\n",
    "prediction4 = baggingClassifier4.predict(Weighted_XTest[Weighted_XTest.columns[idxs_selected4]])\n",
    "print (prediction4)\n",
    "prediction5 = baggingClassifier5.predict(Weighted_XTest[Weighted_XTest.columns[idxs_selected5]])\n",
    "print (prediction5)\n",
    "total = prediction1+prediction2+prediction3+prediction4+prediction5\n",
    "print (total)\n",
    "totalNew = []\n",
    "for value in total:\n",
    "    if value > 2:\n",
    "        totalNew.append('Y')\n",
    "    else:\n",
    "        totalNew.append('N')\n",
    "print (np.array(totalNew))\n",
    "print (np.array(X_test['Class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896551724137931"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.array(X_test['Class']),np.array(totalNew))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=11, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomForest1 = RandomForestClassifier(n_estimators=11,n_jobs=-1,random_state=0)\n",
    "randomForest2 = RandomForestClassifier(n_estimators=11,n_jobs=-1,random_state=0)\n",
    "randomForest3 = RandomForestClassifier(n_estimators=11,n_jobs=-1,random_state=0)\n",
    "randomForest4 = RandomForestClassifier(n_estimators=11,n_jobs=-1,random_state=0)\n",
    "randomForest5 = RandomForestClassifier(n_estimators=11,n_jobs=-1,random_state=0)\n",
    "randomForest1.fit(X_new1,Y_train1)\n",
    "randomForest2.fit(X_new2,Y_train2)\n",
    "randomForest3.fit(X_new3,Y_train3)\n",
    "randomForest4.fit(X_new4,Y_train4)\n",
    "randomForest5.fit(X_new5,Y_train5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83571429 0.65714286 0.57142857]\n"
     ]
    }
   ],
   "source": [
    "scores1 = cross_val_score(randomForest1, X_new1, Y_train1)\n",
    "scores2 = cross_val_score(randomForest2, X_new2, Y_train2)\n",
    "scores3 = cross_val_score(randomForest3, X_new3, Y_train3)\n",
    "scores4 = cross_val_score(randomForest4, X_new4, Y_train4)\n",
    "scores5 = cross_val_score(randomForest5, X_new5, Y_train5)\n",
    "\n",
    "avg = (scores1 + scores2 +scores3 + scores4 + scores5)/5\n",
    "\n",
    "print avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 1 1 1 0 1 1 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0]\n",
      "[1 1 2 5 4 4 2 3 3 3 3 1 2 3 3 3 4 5 2 3 5 5 5 5 5 5 4 5 4]\n",
      "['N' 'N' 'N' 'Y' 'Y' 'Y' 'N' 'Y' 'Y' 'Y' 'Y' 'N' 'N' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
      " 'N' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y']\n",
      "['N' 'N' 'N' 'N' 'Y' 'Y' 'Y' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y']\n"
     ]
    }
   ],
   "source": [
    "prediction1 = randomForest1.predict(Weighted_XTest[Weighted_XTest.columns[idxs_selected1]])\n",
    "print (prediction1)\n",
    "prediction2 = randomForest2.predict(Weighted_XTest[Weighted_XTest.columns[idxs_selected2]])\n",
    "print (prediction2)\n",
    "prediction3 = randomForest3.predict(Weighted_XTest[Weighted_XTest.columns[idxs_selected3]])\n",
    "print (prediction3)\n",
    "prediction4 = randomForest4.predict(Weighted_XTest[Weighted_XTest.columns[idxs_selected4]])\n",
    "print (prediction4)\n",
    "prediction5 = randomForest5.predict(Weighted_XTest[Weighted_XTest.columns[idxs_selected5]])\n",
    "print (prediction5)\n",
    "total = prediction1+prediction2+prediction3+prediction4+prediction5\n",
    "print (total)\n",
    "totalNew = []\n",
    "for value in total:\n",
    "    if value > 2:\n",
    "        totalNew.append('Y')\n",
    "    else:\n",
    "        totalNew.append('N')\n",
    "print (np.array(totalNew))\n",
    "print (np.array(X_test['Class']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5862068965517241"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.array(X_test['Class']),np.array(totalNew))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianProcessClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessClassifier(copy_X_train=True,\n",
       "             kernel=1**2 * RBF(length_scale=0.5), max_iter_predict=100,\n",
       "             multi_class='one_vs_rest', n_jobs=1, n_restarts_optimizer=0,\n",
       "             optimizer='fmin_l_bfgs_b', random_state=None,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_opt1 = GaussianProcessClassifier(kernel=1.0 * RBF(length_scale=0.5))\n",
    "gp_opt2 = GaussianProcessClassifier(kernel=1.0 * RBF(length_scale=0.5))\n",
    "gp_opt3 = GaussianProcessClassifier(kernel=1.0 * RBF(length_scale=0.5))\n",
    "gp_opt4 = GaussianProcessClassifier(kernel=1.0 * RBF(length_scale=0.5))\n",
    "gp_opt5 = GaussianProcessClassifier(kernel=1.0 * RBF(length_scale=0.5))\n",
    "gp_opt1.fit(X_new1,Y_train1)\n",
    "gp_opt2.fit(X_new2,Y_train2)\n",
    "gp_opt3.fit(X_new3,Y_train3)\n",
    "gp_opt4.fit(X_new4,Y_train4)\n",
    "gp_opt5.fit(X_new5,Y_train5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33214286 0.31428571 0.28571429]\n"
     ]
    }
   ],
   "source": [
    "scores1 = cross_val_score(gp_opt1, X_new1, Y_train1)\n",
    "scores2 = cross_val_score(gp_opt2, X_new2, Y_train2)\n",
    "scores3 = cross_val_score(gp_opt3, X_new3, Y_train3)\n",
    "scores4 = cross_val_score(gp_opt4, X_new4, Y_train4)\n",
    "scores5 = cross_val_score(gp_opt5, X_new5, Y_train5)\n",
    "\n",
    "avg = (scores1 + scores2 +scores3 + scores4 + scores5)/5\n",
    "print avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "['N' 'N' 'N' 'N' 'Y' 'Y' 'Y' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y']\n"
     ]
    }
   ],
   "source": [
    "prediction1 = gp_opt1.predict(Weighted_XTest[Weighted_XTest.columns[idxs_selected1]])\n",
    "print (prediction1)\n",
    "prediction2 = gp_opt2.predict(Weighted_XTest[Weighted_XTest.columns[idxs_selected2]])\n",
    "print (prediction2)\n",
    "prediction3 = gp_opt3.predict(Weighted_XTest[Weighted_XTest.columns[idxs_selected3]])\n",
    "print (prediction3)\n",
    "prediction4 = gp_opt4.predict(Weighted_XTest[Weighted_XTest.columns[idxs_selected4]])\n",
    "print (prediction4)\n",
    "prediction5 = gp_opt5.predict(Weighted_XTest[Weighted_XTest.columns[idxs_selected5]])\n",
    "print (prediction5)\n",
    "total = prediction1+prediction2+prediction3+prediction4+prediction5\n",
    "print (total)\n",
    "totalNew = []\n",
    "for value in total:\n",
    "    if value > 1:\n",
    "        totalNew.append('Y')\n",
    "    else:\n",
    "        totalNew.append('N')\n",
    "print (np.array(totalNew))\n",
    "print (np.array(X_test['Class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5862068965517241"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.array(X_test['Class']),np.array(totalNew))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = svm.SVC(kernel='rbf', gamma=1)\n",
    "model2 = svm.SVC(kernel='rbf', gamma=1)\n",
    "model3 = svm.SVC(kernel='rbf', gamma=1)\n",
    "model4 = svm.SVC(kernel='rbf', gamma=1)\n",
    "model5 = svm.SVC(kernel='rbf', gamma=1)\n",
    "model1.fit(X_new1,Y_train1)\n",
    "model2.fit(X_new2,Y_train2)\n",
    "model3.fit(X_new3,Y_train3)\n",
    "model4.fit(X_new4,Y_train4)\n",
    "model5.fit(X_new5,Y_train5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69642857 0.71428571 0.71428571]\n"
     ]
    }
   ],
   "source": [
    "scores1 = cross_val_score(model1, X_new1, Y_train1)\n",
    "scores2 = cross_val_score(model2, X_new2, Y_train2)\n",
    "scores3 = cross_val_score(model3, X_new3, Y_train3)\n",
    "scores4 = cross_val_score(model4, X_new4, Y_train4)\n",
    "scores5 = cross_val_score(model5, X_new5, Y_train5)\n",
    "\n",
    "avg = (scores1 + scores2 +scores3 + scores4 + scores5)/5\n",
    "print avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "['N' 'N' 'N' 'N' 'Y' 'Y' 'Y' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y']\n"
     ]
    }
   ],
   "source": [
    "prediction1 = model1.predict(Weighted_XTest[Weighted_XTest.columns[idxs_selected1]])\n",
    "print (prediction1)\n",
    "prediction2 = model2.predict(Weighted_XTest[Weighted_XTest.columns[idxs_selected2]])\n",
    "print (prediction2)\n",
    "prediction3 = model3.predict(Weighted_XTest[Weighted_XTest.columns[idxs_selected3]])\n",
    "print (prediction3)\n",
    "prediction4 = model4.predict(Weighted_XTest[Weighted_XTest.columns[idxs_selected4]])\n",
    "print (prediction4)\n",
    "prediction5 = model5.predict(Weighted_XTest[Weighted_XTest.columns[idxs_selected5]])\n",
    "print (prediction5)\n",
    "print (np.array(X_test['Class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5862068965517241"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.array(X_test['Class']),np.array(totalNew))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
